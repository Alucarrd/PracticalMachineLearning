install.packages("swirl")
packageVersion("swirl")
library(swirl)
install_from_swirl("Regression Models")
swirl
swirl()
plot(child ~ parent, galton)
plot(jitter(child, 4) ~ parent, galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
regressionLine <- lm(child ~ parent, galton)
fit <- lm(child ~ parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
lhs
lhs - rhs
all.equal(lhs, rhs)
varChild <- var(child, null, false, galton)
varChild <- var(galton$child, null, false, use)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild, varRes, varEst)
all.equal(varChild, varRes+varEst)
efit <- lm(accel ~ mag+dist, attenu)
mean(efit)
mean(efit$residuals)
cov(attenu$mag)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
fit <- lm(child ~ parent, galton)
sqrt(sum(fit$residuals^2)/(n-2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sTot <- sum((galton$child - mu)^2)
sRes <- deviance(fit)
1 - (sRes/sTot)
1-sRes/sTot
summary(fit)$r.squared
cor(galton$child, galton$parent)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent -1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
head(trees)
fit <- lm(Volume ~ Girth + height + Constant -1, trees)
fit <- lm(Volume ~ Girth + Height + Constant -1, trees)
threes2 <- eliminate("Girth", trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant -1, tree2)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
lm(Fertility ~ ., swiss)
all <- lm(Fertility ~ ., swiss)
summary(all)
summary(lm(Fertility ~ Agriculture, swiss))
cor(swiss$Examination, swiss$Education)
cor(swiss$, swiss$Education)
cor(swiss$Agriculture, swiss$Education)
malelms()
makelms
makelms()
ec <- sum(swiss$Examination, swiss$Catholic)
ec <- swiss$Examination+ swiss$Catholic
efit <- lm(Fertility ~ .+ec, swiss)
all$coefficients - efit$coefficients
swirl()
load(swirl)
library(swirl)
swirl(0)
rgp1()
rgp2()
head(swiss)
mdl <- lm(Fertility ~ . + 1, swiss)
vif(mdl)
mdl2 <- lm( Fertility ~ Agriculture + Education + Catholic + infant.Mortality, swiss)
mdl2 <- lm( Fertility ~ Agriculture + Education + Catholic + Infant.Mortality, swiss)
vif(mdl2)
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
View(ravenData)
mdl <- glm(ravenWinNum ~ ravenScore, binomial, ravenData)
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
confint(mdl)
exp(conflint(mdl))
exp(confint(mdl))
anova(mdl)
qchisq(.95, 1)
var(rpois(1000, 50))
head(hits)
class(hits[,'date'])
as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
exp(confint(mdl, 'date'))
which.max(hits[, 'visits'])
hits[704,]
lambda <- mdl$fitted.values[704]
qpois(.95, lambda)
mdl2 <- glm(visits ~ date, poisson, hits, offset=log(visits+1))
mdl2 <- glm(simplystats ~ date, poisson, hits, offset=log(visits+1))
qpois(.95, mdl2$fitted.values[704])
install.packages("caret", dependencies = true)
install.packages("caret")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
library("caret")
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
head(training)
head(testing)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(ggplot2)
library(lattice)
data(AlzheimerDisease)
set.seed(965)
qplot(CompressiveStrength, Cement, data=concrete)
index <- colname(Concrete[, c(1, 2, 3, 4, 5, 6, 7)])
index <- colnames(Concrete[, c(1, 2, 3, 4, 5, 6, 7)])
index <- colnames(concrete[, c(1, 2, 3, 4, 5, 6, 7)])
featurePlot(x=training[,index], y=training$CompressiveStrength, plot="pairs")
library(gridExtra)
install.packages(gridExtra)
par(mfrow= c(2, 1), mar= c(4, 2, 2, 2))
hist(training$Superplasticizer, main="")
hist(log(training$Superplasticizer+1), main="")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
predName <- names(training)
(ILpredictor <- predName[substr(predName, 1, 2)=="IL"])
ProcPCA <- preProcess(training[, ILpredictor], method="pca", thresh=.9)
ProcPCA
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training) value=TRUE)
IL_str <- grep("^IL", colnames(training) ,value=TRUE)
predictor_IL <- predictors[, IL_str ]
df <- data.frame(diagnosis, predictor_IL)
head(df)
inTrain = createDataPartition(df$diagnosis, p=3/4)[[1]]
inTrain
training = df[inTrain,]
testing = df[-inTrain,]
modelFit <- train(diagnosis ~ ., method="glm, data=training")
modelFit <- train(diagnosis ~ ., method="glm", data=training")
c
;
;
modelFit <- train(diagnosis ~ ., method="glm", data=training)
install.packages(e1071)
install.packages("e1071")
modelFit <- train(diagnosis ~ ., method="glm", data=training)
modelFit
trainingIL <- training[, c(ILpredictor, "diagnosis")]
testingIL <- testing[, c(ILpredictor, "diagnosis")]
ModelAll <- train(diagnosis ~ ., data=trainingIL, method="glm")
confusionMatrix(testingIL$diagnosis, predict(ModelAll, testingIL))
install.packages("AppliedPredictiveModeling")
install.packages("caret")
install.packages("ElemStatLearn")
install.packages("pgmm")
install.packages("rpart")
sessionInfo()
library(AppliedPredictiveModeling)
sessionInfo()
library(caret)
sessionInfo()
data("segmentationOriginal")
data(segmentationOriginal)
sessionInfo()
inTrain <- createDataPartition(y = segmentationOriginal$Case, p=.7, list=FALSE)
set.seed(125)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
modelFit <- train(Class ~ ., method="rpart", data = training)
head(training)
modelFit$finalModel
getTree(modelFit$finalModel, k = 2)
library(rpart.plot)
library(rattle)
install.packages("rattle")
fancyRpartPlot(modelFit$finalModel)
library(rpart.plot)
library(rattle)
library(rattle)
fancyRpartPlot(modelFit$finalModel)
library(rpart.plot)
library(rpart)
fancyRpartPlot(modelFit$finalModel)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modelFit$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
names(olive)
model <- train(Area ~ ., data=olive, method="rpart")
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata)
library(ElemStatLearn)
data("SAheart")
set.seed(8484)
train = sample(1:dim(SAheart)[1], size=dim(SAheart)[1]/2, replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
names(trainSA)
model <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, method="glm" data=trainSA, family="binomial", verbose=FALSE)
model <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, method="glm", data=trainSA, family="binomial", verbose=FALSE)
model <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, method="glm", data=trainSA, family="binomial", verbose=FALSE)
set.seed(1234)
model <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, method="glm", data=trainSA, family="binomial", verbose=FALSE)
head(trainSA)
model <- train(chd~age+alcohol+obesity+tobacco+typea+ldl, method="glm", data=trainSA, family="binomial", verbose=FALSE)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
#SAheart<-SAheart[c("age", "alcohol", "obesity", "tobacco", "typea", "ldl", "chd")]
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(1234)
model <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
set.seed(13234)
model <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predict(model, trainSA))
missClass(testSA$chd, predict(model, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel = rbind(vowel.test, vowel.train)
vowel$y = factor(vowel$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
fit <= randomForest(y~., data=vowel.train)
fit <- randomForest(y~., data=vowel.train)
modelFit <- train(y ~ ., data=vowel.train, method="rf", prox=TRUE)
modelFit <- train(y ~ ., data=vowel.train, method="rf", prox=TRUE)
imps <- varImp(modelFit)
order(imps)
imps
vowel.test$y = factor(vowel.test$y)
result <- predict(modelFit, vowel.test)
varImp(modelFit)
vowel.train$y = as.factor(vowel.train$y)
modelFit <- train(y ~ ., data=vowel.train, method="rf")
varImp(modelFit)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y<- as.factor(vowel.train$y)
vowel.test$y<- as.factor(vowel.test$y)
modelFit4<- train(y~.,data=vowel.train,method="rf")
varImp(modelFit4)
modelFit <- randomForest(y ~ ., data=vowel.train)
varImp((modelFit))
modelFit <- randomForest(y ~ ., data=vowel.train)
varImp((modelFit))
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData <- data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p=.75)[[1]]
training = adData[inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modrf <- train(diagnosis, data=training, method="rf")
modrf <- train(diagnosis ~ ., data=training, method="rf")
modgbm <- train(diagnosis ~ ., data=training, method="gbm")
modlda <- suppressMessages(train(diagnosis ~ ., data=training, method="lda"))
pred.rf <- predict(modrf, testing)
pred.gbm <- predict(modgbm, testing)
pred.lda <- predict(modlda, testing)
combine.data <- data.frame(pred.rf, pred.gbm, pred.lda, diagnosis <- testing$diagnosis)
combine.model <- train(diagosis ~ ., method="rf", data=combine.data)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rfmodel <- suppressMessages(train(diagnosis~., data=training, method="rf"))
gbmmodel <- suppressMessages(train(diagnosis~., data=training, method="gbm"))
ldamodel <- suppressMessages(train(diagnosis~., data=training, method="lda"))
rfresult <- predict(rfmodel, testing)
gbmresult <- predict(gbmmodel, testing)
ldaresult <- predict(ldamodel, testing)
combined.data <- data.frame(rfresult, gbmresult, ldaresult, diagnosis=testing$diagnosis)
combined.model <- train(diagnosis~., data=combined.data, method="rf")
combine.predict <- predict(combined.model, testing)
confusionMatrix(testing$diagnosis, rfresult)$overall
confusionMatrix(testing$diagnosis, gbmresult)$overall
confusionMatrix(testing$diagnosis, ldaresult)$overall
confusionMatrix(testing$diagnosis, combine.predict$result)$overall
confusionMatrix(testing$diagnosis, combine.predict)$overall
getwd()
library(lubricate)
library(lubridate)
install.packages("lubridate")
library(lubridate)
dat <- read.csv("data/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
install.packages("forecast")
install.packages("quantmod")
library(forecast)
library(quantmod)
setwd("/Users/petinatan/data/DataScience/")
source("PracticalMachineLearning.R")
dim(training)
badColumns <- nearZeroVar(training, saveMetrics = TRUE)
head(badColumns)
source("PracticalMachineLearning.R")
source("PracticalMachineLearning.R")
source("PracticalMachineLearning.R")
confusionMatrix(predictGBM, testing$classe)
source("PracticalMachineLearning.R")
modelRF <- randomForest(classe ~ ., data=training, method="class")
predRF <- predict(modelRF, testing$classe, type="class")
head(testing)
dim(testing)
tail(teting)
tail(testing)
dim(testing)
testing[testing == '']  <- 0
testing[testing == '']  <- 0
dim(testing)
tail(testing)
source("PracticalMachineLearning.R")
head(trainingData)
trainingData[trainingData ==''] <- 0
head(trainingData)
trainingData[is.na(trainingData)] <- 0
head(trainingData)
trainingData[trainingData =='<NA>'] <- 0
head(trainingData)
trainingData[!is.numeric(trainingData)] <- 0
head(trainingData)
trainingData[!is.double(trainingData)] <- 0
source("PracticalMachineLearning.R")
trainingData[!is.double(trainingData)] <- 0
testingData[!is.double(testingData)] <- 0
head(trainingData)
head(trainingData)
source("PracticalMachineLearning.R")
head(trainingData)
trainingData[is.na(trainingData) | trainingData == ""] <- 0
head(trainingData)
source("PracticalMachineLearning.R")
head(trainingData)
source("PracticalMachineLearning.R")
head(trainingData)
source("PracticalMachineLearning.R")
head(trainingData)
source("PracticalMachineLearning.R")
head(trainingData)
source("PracticalMachineLearning.R")
head(trainingData)
source("PracticalMachineLearning.R")
source("PracticalMachineLearning.R")
confusionMatrix(model.rpart)
confusionMatrix(predict.rpart, testing$classe)
install.packages("knitr")
source("PracticalMachineLearning.R")
head(testingData)
